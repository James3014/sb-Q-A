#!/usr/bin/env python3
"""
ä½¿ç”¨å…§å®¹æ¯”å°æ‰¾å‡ºçœŸæ­£ç¼ºå¤±çš„é€å­—ç¨¿æª”æ¡ˆ
"""

import json
import glob
from pathlib import Path
from difflib import SequenceMatcher

def extract_content_from_cleaned(file_path):
    """å¾å·²æ•´ç†çš„markdownæª”æ¡ˆä¸­æå–åŸå§‹å…§å®¹æ‘˜è¦"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # æå– Drill_How éƒ¨åˆ†çš„å…§å®¹ä½œç‚ºæ¯”å°ä¾æ“š
        # å› ç‚ºé€™éƒ¨åˆ†æœ€æ¥è¿‘åŸå§‹é€å­—ç¨¿çš„å…§å®¹
        if '## ğŸ› ï¸ æ€éº¼ç·´ Drill_How' in content:
            drill_start = content.find('## ğŸ› ï¸ æ€éº¼ç·´ Drill_How')
            drill_end = content.find('## âœ…', drill_start)
            if drill_end == -1:
                drill_end = content.find('## ğŸ“š', drill_start)
            if drill_end == -1:
                drill_content = content[drill_start:]
            else:
                drill_content = content[drill_start:drill_end]

            # æ¸…ç†markdownæ ¼å¼ï¼Œåªä¿ç•™æ–‡å­—
            drill_content = drill_content.replace('## ğŸ› ï¸ æ€éº¼ç·´ Drill_How', '')
            drill_content = drill_content.replace('**', '')
            drill_content = drill_content.replace('- ', '')
            drill_content = drill_content.strip()

            # å–å‰800å­—å…ƒä½œç‚ºæ¯”å°å…§å®¹
            return drill_content[:800]

        # å¦‚æœæ²’æœ‰æ‰¾åˆ° Drill_Howï¼Œå°±å–æ•´å€‹æ–‡ä»¶çš„å‰800å­—å…ƒ
        return content[:800]
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return ""

def extract_content_from_transcript(file_path):
    """å¾åŸå§‹é€å­—ç¨¿ä¸­æå–å…§å®¹æ‘˜è¦"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        # å–å‰800å­—å…ƒä½œç‚ºæ¯”å°å…§å®¹
        return content[:800].strip()
    except Exception as e:
        print(f"Error reading {file_path}: {e}")
        return ""

def find_best_match(transcript_content, cleaned_contents):
    """æ‰¾å‡ºèˆ‡é€å­—ç¨¿å…§å®¹æœ€ç›¸ä¼¼çš„å·²æ•´ç†æª”æ¡ˆ"""
    best_ratio = 0
    best_file = None

    for cleaned_file, cleaned_content in cleaned_contents.items():
        ratio = SequenceMatcher(None, transcript_content, cleaned_content).ratio()
        if ratio > best_ratio:
            best_ratio = ratio
            best_file = cleaned_file

    return best_file, best_ratio

def main():
    # è®€å–ç–‘ä¼¼æœªè™•ç†çš„é€å­—ç¨¿æ¸…å–®
    with open('/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/unmatched_transcripts.json', 'r', encoding='utf-8') as f:
        data = json.load(f)
        unmatched_files = data['unmatched_files']

    print(f"ç–‘ä¼¼æœªè™•ç†çš„é€å­—ç¨¿æ•¸é‡: {len(unmatched_files)}")

    # è®€å–æ‰€æœ‰å·²æ•´ç†çš„æª”æ¡ˆå…§å®¹
    cleaned_dir = Path('/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/sam_cleaned')
    cleaned_files = sorted(glob.glob(str(cleaned_dir / '*.md')))

    print(f"å·²æ•´ç†çš„æª”æ¡ˆæ•¸é‡: {len(cleaned_files)}")
    print("æ­£åœ¨è®€å–å·²æ•´ç†æª”æ¡ˆçš„å…§å®¹...")

    cleaned_contents = {}
    for cf in cleaned_files:
        content = extract_content_from_cleaned(cf)
        if content:
            cleaned_contents[Path(cf).name] = content

    print(f"æˆåŠŸè®€å– {len(cleaned_contents)} å€‹å·²æ•´ç†æª”æ¡ˆçš„å…§å®¹")

    # æ¯”å°æ¯å€‹ç–‘ä¼¼æœªè™•ç†çš„é€å­—ç¨¿
    sam_dir = Path('/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/sam')
    truly_missing = []
    matched_files = []

    print("\né–‹å§‹å…§å®¹æ¯”å°...")
    for i, unmatched_file in enumerate(unmatched_files, 1):
        transcript_path = sam_dir / unmatched_file
        transcript_content = extract_content_from_transcript(transcript_path)

        if not transcript_content:
            print(f"[{i}/{len(unmatched_files)}] ç„¡æ³•è®€å–: {unmatched_file}")
            continue

        best_file, best_ratio = find_best_match(transcript_content, cleaned_contents)

        print(f"[{i}/{len(unmatched_files)}] {unmatched_file}")
        print(f"  æœ€ä½³åŒ¹é…: {best_file} (ç›¸ä¼¼åº¦: {best_ratio:.1%})")

        # ç›¸ä¼¼åº¦ < 50% è¦–ç‚ºçœŸæ­£ç¼ºå¤±çš„æª”æ¡ˆ
        if best_ratio < 0.50:
            truly_missing.append({
                'file': unmatched_file,
                'best_match': best_file,
                'similarity': round(best_ratio, 3)
            })
        else:
            matched_files.append({
                'file': unmatched_file,
                'matched_to': best_file,
                'similarity': round(best_ratio, 3)
            })

    # è¼¸å‡ºçµæœ
    result = {
        'total_suspected': len(unmatched_files),
        'truly_missing_count': len(truly_missing),
        'actually_matched_count': len(matched_files),
        'truly_missing': truly_missing,
        'actually_matched': matched_files
    }

    output_path = '/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/truly_missing_transcripts.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)

    print(f"\n{'='*60}")
    print(f"ç–‘ä¼¼æœªè™•ç†çš„é€å­—ç¨¿: {len(unmatched_files)} å€‹")
    print(f"å¯¦éš›ä¸Šå·²æœ‰å°æ‡‰æ•´ç†æª”æ¡ˆ: {len(matched_files)} å€‹")
    print(f"çœŸæ­£ç¼ºå¤±çš„é€å­—ç¨¿: {len(truly_missing)} å€‹")
    print(f"\nçµæœå·²å„²å­˜è‡³: {output_path}")
    print(f"{'='*60}")

    if truly_missing:
        print("\nçœŸæ­£ç¼ºå¤±çš„æª”æ¡ˆæ¸…å–®:")
        for item in truly_missing:
            print(f"  - {item['file']} (æœ€é«˜ç›¸ä¼¼åº¦åƒ… {item['similarity']:.1%})")

if __name__ == '__main__':
    main()
