#!/usr/bin/env python3
"""
é‡å»º sam é€å­—ç¨¿èˆ‡ sam_cleaned çš„æ­£ç¢ºå°æ‡‰é—œä¿‚
ä½¿ç”¨å…§å®¹ç›¸ä¼¼åº¦æ¯”å°ï¼Œè€Œéæª”å
"""
import os
import json
import re
from difflib import SequenceMatcher

SAM_DIR = "/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/sam"
CLEANED_DIR = "/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/sam_cleaned"
OUTPUT_FILE = "/Users/jameschen/Downloads/å–®æ¿æ•™å­¸/correct_mapping.json"

def clean_text(text):
    """æ¸…ç†æ–‡å­—ç”¨æ–¼æ¯”å°ï¼ˆç§»é™¤æ¨™é»ã€ç©ºç™½ã€è½‰ç°¡é«”ï¼‰"""
    # ç§»é™¤ markdown æ¨™è¨˜
    text = re.sub(r'[#*_\-\[\]()]', '', text)
    # ç§»é™¤ç©ºç™½
    text = re.sub(r'\s+', '', text)
    return text.lower()

def extract_key_phrases(text):
    """æå–é—œéµè©çµ„ï¼ˆç”¨æ–¼å¿«é€Ÿç¯©é¸ï¼‰"""
    # æå–ä¸­æ–‡è©çµ„ï¼ˆ3-8å­—ï¼‰
    phrases = re.findall(r'[\u4e00-\u9fff]{3,8}', text)
    return set(phrases[:50])  # å–å‰50å€‹

def similarity_score(text1, text2):
    """è¨ˆç®—å…©æ®µæ–‡å­—çš„ç›¸ä¼¼åº¦"""
    clean1 = clean_text(text1)
    clean2 = clean_text(text2)
    
    # ä½¿ç”¨ SequenceMatcher
    return SequenceMatcher(None, clean1, clean2).ratio()

def find_best_match(sam_content, cleaned_files_content):
    """æ‰¾å‡ºæœ€ä½³åŒ¹é…çš„ cleaned æª”æ¡ˆ"""
    best_match = None
    best_score = 0
    
    sam_phrases = extract_key_phrases(sam_content)
    
    for cleaned_file, cleaned_content in cleaned_files_content.items():
        # å¿«é€Ÿç¯©é¸ï¼šé—œéµè©é‡ç–Šåº¦
        cleaned_phrases = extract_key_phrases(cleaned_content)
        overlap = len(sam_phrases & cleaned_phrases)
        
        if overlap < 3:  # è‡³å°‘3å€‹é—œéµè©é‡ç–Š
            continue
            
        # è©³ç´°æ¯”å°
        score = similarity_score(sam_content, cleaned_content)
        
        if score > best_score:
            best_score = score
            best_match = cleaned_file
    
    return best_match, best_score

def main():
    print("ğŸ” é–‹å§‹é‡å»ºå°æ‡‰é—œä¿‚...")
    
    # è®€å–æ‰€æœ‰ sam æª”æ¡ˆ
    sam_files = {}
    for filename in os.listdir(SAM_DIR):
        if filename.endswith('.txt') and not filename.startswith('.'):
            filepath = os.path.join(SAM_DIR, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                sam_files[filename] = f.read()
    
    print(f"âœ… è®€å– {len(sam_files)} å€‹ sam æª”æ¡ˆ")
    
    # è®€å–æ‰€æœ‰ cleaned æª”æ¡ˆ
    cleaned_files = {}
    for filename in os.listdir(CLEANED_DIR):
        if filename.endswith('.md') and re.match(r'^\d+_', filename):
            filepath = os.path.join(CLEANED_DIR, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                cleaned_files[filename] = f.read()
    
    print(f"âœ… è®€å– {len(cleaned_files)} å€‹ cleaned æª”æ¡ˆ")
    
    # å»ºç«‹å°æ‡‰é—œä¿‚
    mapping = {}
    used_cleaned = set()
    
    for i, (sam_file, sam_content) in enumerate(sam_files.items(), 1):
        print(f"[{i}/{len(sam_files)}] æ¯”å° {sam_file}...", end=' ')
        
        # æ’é™¤å·²ä½¿ç”¨çš„æª”æ¡ˆ
        available_cleaned = {k: v for k, v in cleaned_files.items() if k not in used_cleaned}
        
        best_match, score = find_best_match(sam_content, available_cleaned)
        
        if best_match and score > 0.3:  # ç›¸ä¼¼åº¦é–¾å€¼
            mapping[sam_file] = {
                "cleaned_file": best_match,
                "similarity": round(score, 3)
            }
            used_cleaned.add(best_match)
            print(f"âœ… {best_match} (ç›¸ä¼¼åº¦: {score:.2%})")
        else:
            mapping[sam_file] = {
                "cleaned_file": None,
                "similarity": 0
            }
            print(f"âŒ æ‰¾ä¸åˆ°åŒ¹é…")
    
    # æ‰¾å‡ºæœªåŒ¹é…çš„ cleaned æª”æ¡ˆ
    unmatched_cleaned = set(cleaned_files.keys()) - used_cleaned
    
    # å„²å­˜çµæœ
    result = {
        "mapping": mapping,
        "unmatched_cleaned": sorted(list(unmatched_cleaned)),
        "stats": {
            "total_sam": len(sam_files),
            "total_cleaned": len(cleaned_files),
            "matched": len(used_cleaned),
            "unmatched_sam": len([v for v in mapping.values() if v["cleaned_file"] is None]),
            "unmatched_cleaned": len(unmatched_cleaned)
        }
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ“Š çµ±è¨ˆï¼š")
    print(f"  - Sam æª”æ¡ˆç¸½æ•¸: {result['stats']['total_sam']}")
    print(f"  - Cleaned æª”æ¡ˆç¸½æ•¸: {result['stats']['total_cleaned']}")
    print(f"  - æˆåŠŸé…å°: {result['stats']['matched']}")
    print(f"  - æœªé…å° Sam: {result['stats']['unmatched_sam']}")
    print(f"  - æœªé…å° Cleaned: {result['stats']['unmatched_cleaned']}")
    print(f"\nâœ… å°æ‡‰é—œä¿‚å·²å„²å­˜è‡³: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
